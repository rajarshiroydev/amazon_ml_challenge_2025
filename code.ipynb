{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import urllib\n",
    "import warnings\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import multiprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "VRAM: 79.1 GB\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Loading Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 75,000, Test: 75,000\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "print(\"[1/7] Loading Data\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f\"Train: {len(train_df):,}, Test: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] Extracting item_name, bullet_points and product_description from catalog_content column\n"
     ]
    }
   ],
   "source": [
    "# Extracting item_name, bullet_points and product_description from catalog_content column\n",
    "print(\"[2/7] Extracting item_name, bullet_points and product_description from catalog_content column\")\n",
    "\n",
    "def extract_fields(text):\n",
    "    \"\"\"Extract Item Name, Bullet Points, and Product Description from the string.\"\"\"\n",
    "    item_name_match = re.search(r\"Item Name:\\s*(.+?)(?:\\n|$)\", text)\n",
    "    item_name = item_name_match.group(1).strip() if item_name_match else None\n",
    "\n",
    "    # Capture all bullet points with flexible numbering or single 'Bullet Point'\n",
    "    bullets = re.findall(r\"Bullet Point\\s*\\d*:\\s*(.+)\", text)\n",
    "    bullet_points = [b.strip() for b in bullets] if bullets else []\n",
    "\n",
    "    # Capture product description\n",
    "    prod_desc_match = re.search(r\"Product Description:\\s*(.+)\", text, re.DOTALL)\n",
    "    prod_desc = prod_desc_match.group(1).strip() if prod_desc_match else None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"item_name\": item_name,\n",
    "        \"bullet_points\": bullet_points if bullet_points else None,\n",
    "        \"product_description\": prod_desc\n",
    "    })\n",
    "\n",
    "# extract fields from product_description of train data\n",
    "df_extracted = train_df[\"catalog_content\"].apply(extract_fields)\n",
    "train_df = pd.concat([train_df, df_extracted], axis=1)\n",
    "\n",
    "# extract fields from product_description of test data\n",
    "df_extracted = test_df[\"catalog_content\"].apply(extract_fields)\n",
    "test_df = pd.concat([test_df, df_extracted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Downloading Images\n",
      "Downloading 75,000 train images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  49%|████▉     | 36880/75000 [00:01<00:01, 33079.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not able to download - https://m.media-amazon.com/images/I/51mjZYDYjyL.jpg\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 75000/75000 [00:02<00:00, 33292.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 75,000 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading:  54%|█████▍    | 40619/75000 [00:01<00:01, 31668.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not able to download - https://m.media-amazon.com/images/I/813CjSgHj0S.jpg\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 75000/75000 [00:02<00:00, 32606.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Dowloading Images\n",
    "print(\"[3/7] Downloading Images\")\n",
    "\n",
    "def download_image(image_link, savefolder):\n",
    "    if isinstance(image_link, str):\n",
    "        filename = Path(image_link).name\n",
    "        image_save_path = os.path.join(savefolder, filename)\n",
    "        if not os.path.exists(image_save_path):\n",
    "            try:\n",
    "                urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            except Exception as ex:\n",
    "                print(f'Warning: Not able to download - {image_link}\\n{ex}')\n",
    "        return image_save_path\n",
    "    return None\n",
    "\n",
    "def download_images(image_links, download_folder):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    results = []\n",
    "    download_image_partial = partial(download_image, savefolder=download_folder)\n",
    "\n",
    "    with multiprocessing.Pool(100) as pool:\n",
    "        for result in tqdm(pool.imap(download_image_partial, image_links),\n",
    "                          total=len(image_links), desc=\"Downloading\"):\n",
    "            results.append(result)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Download train images\n",
    "train_folder = 'train_images'\n",
    "print(f\"Downloading {len(train_df):,} train images...\")\n",
    "train_image_paths = download_images(train_df['image_link'].tolist(), train_folder)\n",
    "\n",
    "# Download test images\n",
    "test_folder = 'test_images'\n",
    "print(f\"Downloading {len(test_df):,} test images...\")\n",
    "test_image_paths = download_images(test_df['image_link'].tolist(), test_folder)\n",
    "\n",
    "print(\"All images downloaded!\")\n",
    "\n",
    "# Map URLs to local paths\n",
    "train_df['image_path'] = [os.path.join(train_folder, Path(url).name)\n",
    "                          if isinstance(url, str) else None\n",
    "                          for url in train_df['image_link']]\n",
    "test_df['image_path'] = [os.path.join(test_folder, Path(url).name)\n",
    "                         if isinstance(url, str) else None\n",
    "                         for url in test_df['image_link']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>price</th>\n",
       "      <th>item_name</th>\n",
       "      <th>bullet_points</th>\n",
       "      <th>product_description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33127</td>\n",
       "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>La Victoria Green Taco Sauce Mild, 12 Ounce (P...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/51mo8htwTHL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198967</td>\n",
       "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>13.12</td>\n",
       "      <td>Salerno Cookies, The Original Butter Cookies, ...</td>\n",
       "      <td>[Original Butter Cookies: Classic butter cooki...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/71YtriIHAAL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261251</td>\n",
       "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Bear Creek Hearty Soup Bowl, Creamy Chicken wi...</td>\n",
       "      <td>[Loaded with hearty long grain wild rice and v...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/51+PFEe-w-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55858</td>\n",
       "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>30.34</td>\n",
       "      <td>Judee’s Blue Cheese Powder 11.25 oz - Gluten-F...</td>\n",
       "      <td>[Add to your favorite appetizers, dips &amp; sprea...</td>\n",
       "      <td>Judees Powdered Blue Cheese cheddar cheese pow...</td>\n",
       "      <td>train_images/41mu0HAToDL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292686</td>\n",
       "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>66.49</td>\n",
       "      <td>kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...</td>\n",
       "      <td>[kedem Sherry Cooking Wine, 12.7 Ounce - 12 pe...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/41sA037+QvL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
       "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
       "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
       "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
       "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
       "\n",
       "                                          image_link  price  \\\n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89   \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12   \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97   \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34   \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49   \n",
       "\n",
       "                                           item_name  \\\n",
       "0  La Victoria Green Taco Sauce Mild, 12 Ounce (P...   \n",
       "1  Salerno Cookies, The Original Butter Cookies, ...   \n",
       "2  Bear Creek Hearty Soup Bowl, Creamy Chicken wi...   \n",
       "3  Judee’s Blue Cheese Powder 11.25 oz - Gluten-F...   \n",
       "4  kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...   \n",
       "\n",
       "                                       bullet_points  \\\n",
       "0                                               None   \n",
       "1  [Original Butter Cookies: Classic butter cooki...   \n",
       "2  [Loaded with hearty long grain wild rice and v...   \n",
       "3  [Add to your favorite appetizers, dips & sprea...   \n",
       "4  [kedem Sherry Cooking Wine, 12.7 Ounce - 12 pe...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  Judees Powdered Blue Cheese cheddar cheese pow...   \n",
       "4                                               None   \n",
       "\n",
       "                     image_path  \n",
       "0  train_images/51mo8htwTHL.jpg  \n",
       "1  train_images/71YtriIHAAL.jpg  \n",
       "2  train_images/51+PFEe-w-L.jpg  \n",
       "3  train_images/41mu0HAToDL.jpg  \n",
       "4  train_images/41sA037+QvL.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>item_name</th>\n",
       "      <th>bullet_points</th>\n",
       "      <th>product_description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100179</td>\n",
       "      <td>Item Name: Rani 14-Spice Eshamaya's Mango Chut...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71hoAn78AW...</td>\n",
       "      <td>Rani 14-Spice Eshamaya's Mango Chutney (Indian...</td>\n",
       "      <td>[You'll LOVE our 14-Spice Eshamaya's Mango Chu...</td>\n",
       "      <td>Mango chutney is made from diced green mangoes...</td>\n",
       "      <td>test_images/71hoAn78AWL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245611</td>\n",
       "      <td>Item Name: Natural MILK TEA Flavoring extract ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61ex8NHCIj...</td>\n",
       "      <td>Natural MILK TEA Flavoring extract by HALO PAN...</td>\n",
       "      <td>[Authentic Tasting, Asian-Inspired Natural fla...</td>\n",
       "      <td>Check our popular Milk Tea flavoring extract i...</td>\n",
       "      <td>test_images/61ex8NHCIjL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146263</td>\n",
       "      <td>Item Name: Honey Filled Hard Candy - Bulk Pack...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61KCM61J8e...</td>\n",
       "      <td>Honey Filled Hard Candy - Bulk Pack 2 Pounds -...</td>\n",
       "      <td>[Honey Filled Hard Candy; 2-pound bulk pack; a...</td>\n",
       "      <td>Honey Filled Hard Candy - Bulk Pack 2 Pounds -...</td>\n",
       "      <td>test_images/61KCM61J8eL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95658</td>\n",
       "      <td>Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51Ex6uOH7y...</td>\n",
       "      <td>Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test_images/51Ex6uOH7yL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36806</td>\n",
       "      <td>Item Name: McCormick Culinary Vanilla Extract,...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QYlrOMoS...</td>\n",
       "      <td>McCormick Culinary Vanilla Extract, 32 fl oz -...</td>\n",
       "      <td>[PREMIUM INGREDIENTS: McCormick Culinary Pure ...</td>\n",
       "      <td>None</td>\n",
       "      <td>test_images/71QYlrOMoSL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0     100179  Item Name: Rani 14-Spice Eshamaya's Mango Chut...   \n",
       "1     245611  Item Name: Natural MILK TEA Flavoring extract ...   \n",
       "2     146263  Item Name: Honey Filled Hard Candy - Bulk Pack...   \n",
       "3      95658  Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...   \n",
       "4      36806  Item Name: McCormick Culinary Vanilla Extract,...   \n",
       "\n",
       "                                          image_link  \\\n",
       "0  https://m.media-amazon.com/images/I/71hoAn78AW...   \n",
       "1  https://m.media-amazon.com/images/I/61ex8NHCIj...   \n",
       "2  https://m.media-amazon.com/images/I/61KCM61J8e...   \n",
       "3  https://m.media-amazon.com/images/I/51Ex6uOH7y...   \n",
       "4  https://m.media-amazon.com/images/I/71QYlrOMoS...   \n",
       "\n",
       "                                           item_name  \\\n",
       "0  Rani 14-Spice Eshamaya's Mango Chutney (Indian...   \n",
       "1  Natural MILK TEA Flavoring extract by HALO PAN...   \n",
       "2  Honey Filled Hard Candy - Bulk Pack 2 Pounds -...   \n",
       "3    Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)   \n",
       "4  McCormick Culinary Vanilla Extract, 32 fl oz -...   \n",
       "\n",
       "                                       bullet_points  \\\n",
       "0  [You'll LOVE our 14-Spice Eshamaya's Mango Chu...   \n",
       "1  [Authentic Tasting, Asian-Inspired Natural fla...   \n",
       "2  [Honey Filled Hard Candy; 2-pound bulk pack; a...   \n",
       "3                                               None   \n",
       "4  [PREMIUM INGREDIENTS: McCormick Culinary Pure ...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Mango chutney is made from diced green mangoes...   \n",
       "1  Check our popular Milk Tea flavoring extract i...   \n",
       "2  Honey Filled Hard Candy - Bulk Pack 2 Pounds -...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                    image_path  \n",
       "0  test_images/71hoAn78AWL.jpg  \n",
       "1  test_images/61ex8NHCIjL.jpg  \n",
       "2  test_images/61KCM61J8eL.jpg  \n",
       "3  test_images/51Ex6uOH7yL.jpg  \n",
       "4  test_images/71QYlrOMoSL.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\n",
      "Value: 72.0\n",
      "Unit: Fl Oz\n",
      "\n",
      "Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\n",
      "Bullet Point 1: Original Butter Cookies: Classic butter cookies made with real butter\n",
      "Bullet Point 2: Variety Pack: Includes 4 boxes with 32 cookies total\n",
      "Bullet Point 3: Occasion Perfect: Delicious cookies for birthdays, weddings, anniversaries\n",
      "Bullet Point 4: Shareable Treats: Fun to give and enjoy with friends and family\n",
      "Bullet Point 5: Salerno Brand: Trusted brand of delicious butter cookies since 1925\n",
      "Value: 32.0\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\n",
      "Bullet Point 1: Loaded with hearty long grain wild rice and vegetables\n",
      "Bullet Point 2: Full of hearty goodness\n",
      "Bullet Point 3: Single serve bowls\n",
      "Bullet Point 4: Easy to prepare mix\n",
      "Bullet Point 5: 0 grams trans fat\n",
      "Value: 11.4\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: Judee’s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings and Salad Dressings - Great for Dips, Spreads and Sauces - Made in USA\n",
      "Bullet Point 1: Add to your favorite appetizers, dips & spreads. Use to season popcorn or warmed pita chips.\n",
      "Bullet Point 2: Sprinkle over french fries, fried chicken, mashed potatoes, roasted veggies, pasta, and more\n",
      "Bullet Point 3: Made in a dedicated gluten-free facility and shipped in a standup, resealable pouch to ensure freshness\n",
      "Bullet Point 4: Ingredients: Blue Cheese (Milk, Salt, Cultures, & Enzymes) and Disodium Phosphate\n",
      "Bullet Point 5: Since 2009, Judee’s has been dedicated to providing fresh, allergy-conscious ingredients, great for your recipes and even better for your family\n",
      "Product Description: Judees Powdered Blue Cheese cheddar cheese powder is an alternative to mozzarella cheese shredded or american cheese slices deli. Make your own alfredo sauce with heavy cream and black buffalo dip with this powder. It adds extra flavor to salad dressing like ranch dressing and great on pizza dough or cauliflower pasta. Add to macaroni and cheese or popcorn seasoning for more aroma and cheesy feel. Combine with mustard and other ingredients to create your own dressing for buffalo chicken or buffalo wings.\n",
      "Value: 11.25\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\n",
      "Bullet Point: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\n",
      "Value: 12.0\n",
      "Unit: Count\n",
      "\n",
      "Item Name: Member's Mark Member's Mark, Basil, 6.25 oz\n",
      "Bullet Point 1: Green Herb, Italian Staple, Great mixed with Oregano\n",
      "Bullet Point 2: Large Size, Chef Bottle\n",
      "Bullet Point 3: Packed in the USA\n",
      "Value: 6.25\n",
      "Unit: ounce\n",
      "\n",
      "Item Name: Goya Foods Sazonador Total Seasoning, 30 Ounce (Pack of 6)\n",
      "Bullet Point 1: SAZONADOR TOTAL | Enhance the natural flavors of food with the perfect mix of natural ingredients, Goya Sazonador Total. GOYA Sazonador Total adds super flavor in a flash. This versatile seasoning mix includes the perfect blend of Latino spices that makes your meal extra special. We’re sure you’ll love it.\n",
      "Bullet Point 2: THE PERFECT SEASONING | GOYA Sazonador Total is the perfect blend of garlic, onion and Latin spices that adds quick flavor to any meat, chicken, fish and vegetables. Just sprinkle over meats, poultry, seafood and vegetables before cooking. You can also use it to punch up the taste of salads, sauces, and soups. A simple shake is all it takes!\n",
      "Bullet Point 3: VERSATILE | This versatile seasoning mix includes the perfect blend of Latino spices that makes your meal extra special. We’re sure you’ll love it. GOYA Sazonador Total is the perfect blend of garlic, onion and Latin spices that adds quick flavor to any meat, chicken, fish and vegetables.\n",
      "Bullet Point 4: PREMIUM QUALITY | If it's Goya... it has to be good! | ¡Si es Goya... tiene que ser bueno!\n",
      "Bullet Point 5: PACK OF 6: 30 OZ BOTTLES | Discover Goya's incredible variety of seasonings on Amazon Fresh, Amazon Retail and Prime Pantry\n",
      "Value: 180.0\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: VineCo Original Series Chilean Sauvignon Blanc Wine Making Ingredient Kit\n",
      "Bullet Point 1: Chilean Sauvignon Blanc Wine Kit - VineCo Original Series\n",
      "Bullet Point 2: Flavor Profile - Herbaceous, stone fruit and tropical fruit\n",
      "Bullet Point 3: Kit Volume: 8 L, Approximate Yield: 23 L\n",
      "Bullet Point 4: Ready to Bottle: In 4 weeks\n",
      "Bullet Point 5: Ingredient Kit Only Does Not Contain Alcohol\n",
      "Product Description: Chilean Sauvignon Blanc Wine Kit - VineCo Original Series - Unleash the Refreshing Essence of Sauvignon Blanc Known for its vibrant personality, Sauvignon Blanc is a green-skinned grape that embodies the wild spirit of nature. Its name is derived from the French term for \"wild,\" reflecting its unrestrained growth and bold flavors. This grape variety thrives in diverse climates, producing wines that range from crisp and herbaceous to tropical and fruity. In cooler regions, you can expect wines to showcase a lively acidity with green bell pepper and grassy notes, while warmer areas enhance the fruit profile, leading to delightful tropical flavors. Chilean Sauvignon Blanc is particularly celebrated for its citrusy brightness, moving away from the greener characteristics often associated with the grape. Instead, it highlights a luscious mix of stone fruits, passion fruit, and zesty lime, presenting a more refined take on this beloved varietal. The winemaking conditions in Chile, marked by a combination of warm days and cool evenings, allow for optimal ripening while retaining essential acidity. The VineCo Chilean Sauvignon Blanc captures the essence of this grape beautifully. It offers a lively bouquet of herbaceous notes intertwined with enticing flavors of stone fruit and tropical delights. This dry white wine is crafted without oak, maintaining its fresh character. This wine kit encourages you to enjoy the Sauvignon Blanc at its peak freshness. With no aging required, you can indulge in its crisp flavors shortly after bottling. Its versatility means it pairs wonderfully with a variety of dishes, making it a fantastic option for any meal, from light appetizers to vibrant salads and even sushi. Experience the joy of pairing this delightful wine with your culinary creations. Ingredient Kit Only Does Not Contain Alcohol.\n",
      "Value: 1.0\n",
      "Unit: Count\n",
      "\n",
      "Item Name: NATURES PATH CEREAL FLK MULTIGRAIN ORG ECO, 32 OZ, PK- 6\n",
      "Value: 192.0\n",
      "Unit: Fl Oz\n",
      "\n",
      "Item Name: Mrs. Miller's Seedless Black Raspberry Jam 9 Ounce (Pack of 4)\n",
      "Bullet Point 1: Homemade Seedless Black Raspberry Jam made from the finest ripened black raspberries\n",
      "Bullet Point 2: Hand scooped in Ohio’s Amish Country\n",
      "Bullet Point 3: Made with real Cane Sugar\n",
      "Bullet Point 4: Spoon it onto your toast or biscuit, or use it as a tasty glaze on your pork or chicken\n",
      "Bullet Point 5: GMO Free\n",
      "Product Description: Made from the finest ripened black raspberries, Mrs. Miller's Homemade Seedless Black Raspberry Jam packs a delicious sweet taste. Black raspberries possess one of the richest flavors of all fruits, so it is no surprise that this flavor ranks at the top of everyone's list. Spoon it onto your toast or biscuit, or use it as a tasty glaze on your pork or chicken. Don't be surprised if you find yourself licking off the spoon with this one, or even just eating it right out of the jar. Hand scooped in Ohio's Amish Country. Ingredients: Pure Cane Sugar, Black Raspberries, Water, Pectin Lemon Juice, Citric Acid\n",
      "Value: 9.0\n",
      "Unit: Ounce\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the fields present in content_catalog column\n",
    "content_catalog = list(train_df.catalog_content)\n",
    "for i in content_catalog[:10]:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/7] Engineering Value/Unit features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train features: 100%|██████████| 75000/75000 [00:03<00:00, 18950.01it/s]\n",
      "Test features: 100%|██████████| 75000/75000 [00:03<00:00, 19271.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 engineered features\n",
      "Top correlations with price:\n",
      "price             1.000000\n",
      "sqrt_value        0.163218\n",
      "log_value         0.126561\n",
      "log_total_qty     0.107146\n",
      "unit_encoded      0.089220\n",
      "value             0.064510\n",
      "log_pack          0.046921\n",
      "sqrt_total_qty    0.000456\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print(\"[4/7] Engineering Value/Unit features...\")\n",
    "\n",
    "def extract_value_unit_features(text):\n",
    "    \"\"\"Extract critical numeric features with high price correlation\"\"\"\n",
    "    features = {}\n",
    "    text_str = str(text)\n",
    "\n",
    "    # Extract Value\n",
    "    value_match = re.search(r'Value:\\s*([\\d.]+)', text_str)\n",
    "    value = float(value_match.group(1)) if value_match else 0\n",
    "\n",
    "    # Extract Unit\n",
    "    unit_match = re.search(r'Unit:\\s*([^\\n]+)', text_str)\n",
    "    unit = unit_match.group(1).strip() if unit_match else 'unknown'\n",
    "\n",
    "    # Pack quantity patterns\n",
    "    pack_patterns = [\n",
    "        r'pack of (\\d+)', r'\\(pack of (\\d+)\\)', r'(\\d+)[- ]pack',\n",
    "        r'(\\d+) count', r'set of (\\d+)', r'case of (\\d+)',\n",
    "    ]\n",
    "    pack_qty = 1\n",
    "    for pattern in pack_patterns:\n",
    "        matches = re.findall(pattern, text_str.lower())\n",
    "        if matches:\n",
    "            pack_qty = max(pack_qty, max([int(m) for m in matches]))\n",
    "\n",
    "    # Create features\n",
    "    features['value'] = value\n",
    "    features['log_value'] = np.log1p(value)\n",
    "    features['sqrt_value'] = np.sqrt(value)\n",
    "    features['pack_quantity'] = pack_qty\n",
    "    features['log_pack'] = np.log1p(pack_qty)\n",
    "    features['total_quantity'] = value * pack_qty\n",
    "    features['log_total_qty'] = np.log1p(value * pack_qty)\n",
    "    features['sqrt_total_qty'] = np.sqrt(value * pack_qty)\n",
    "    features['unit'] = unit\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = pd.DataFrame([extract_value_unit_features(t)\n",
    "                               for t in tqdm(train_df['catalog_content'],\n",
    "                                           desc=\"Train features\")])\n",
    "test_features = pd.DataFrame([extract_value_unit_features(t)\n",
    "                             for t in tqdm(test_df['catalog_content'],\n",
    "                                         desc=\"Test features\")])\n",
    "\n",
    "# Encode units\n",
    "le = LabelEncoder()\n",
    "all_units = pd.concat([train_features['unit'], test_features['unit']])\n",
    "le.fit(all_units.astype(str))\n",
    "train_features['unit_encoded'] = le.transform(train_features['unit'].astype(str))\n",
    "test_features['unit_encoded'] = le.transform(test_features['unit'].astype(str))\n",
    "\n",
    "train_features = train_features.drop('unit', axis=1)\n",
    "test_features = test_features.drop('unit', axis=1)\n",
    "\n",
    "print(f\"{train_features.shape[1]} engineered features\")\n",
    "\n",
    "# Show correlations\n",
    "train_with_price = train_features.copy()\n",
    "train_with_price['price'] = train_df['price']\n",
    "print(\"Top correlations with price:\")\n",
    "print(train_with_price.corr()['price'].abs().sort_values(ascending=False).head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>sqrt_value</th>\n",
       "      <th>pack_quantity</th>\n",
       "      <th>log_pack</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>log_total_qty</th>\n",
       "      <th>sqrt_total_qty</th>\n",
       "      <th>unit_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.00</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>8.485281</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>432.00</td>\n",
       "      <td>6.070738</td>\n",
       "      <td>20.784610</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.00</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>4</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>128.00</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>11.313708</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.40</td>\n",
       "      <td>2.517696</td>\n",
       "      <td>3.376389</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>68.40</td>\n",
       "      <td>4.239887</td>\n",
       "      <td>8.270429</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.25</td>\n",
       "      <td>2.505526</td>\n",
       "      <td>3.354102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>11.25</td>\n",
       "      <td>2.505526</td>\n",
       "      <td>3.354102</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.00</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  log_value  sqrt_value  pack_quantity  log_pack  total_quantity  \\\n",
       "0  72.00   4.290459    8.485281              6  1.945910          432.00   \n",
       "1  32.00   3.496508    5.656854              4  1.609438          128.00   \n",
       "2  11.40   2.517696    3.376389              6  1.945910           68.40   \n",
       "3  11.25   2.505526    3.354102              1  0.693147           11.25   \n",
       "4  12.00   2.564949    3.464102              1  0.693147           12.00   \n",
       "\n",
       "   log_total_qty  sqrt_total_qty  unit_encoded  \n",
       "0       6.070738       20.784610            46  \n",
       "1       4.859812       11.313708            73  \n",
       "2       4.239887        8.270429            73  \n",
       "3       2.505526        3.354102            73  \n",
       "4       2.564949        3.464102            37  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>sqrt_value</th>\n",
       "      <th>pack_quantity</th>\n",
       "      <th>log_pack</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>log_total_qty</th>\n",
       "      <th>sqrt_total_qty</th>\n",
       "      <th>unit_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2.442347</td>\n",
       "      <td>3.240370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.442347</td>\n",
       "      <td>3.240370</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  log_value  sqrt_value  pack_quantity  log_pack  total_quantity  \\\n",
       "0   10.5   2.442347    3.240370              1  0.693147            10.5   \n",
       "1    2.0   1.098612    1.414214              1  0.693147             2.0   \n",
       "2   32.0   3.496508    5.656854              1  0.693147            32.0   \n",
       "3    2.0   1.098612    1.414214              2  1.098612             4.0   \n",
       "4   32.0   3.496508    5.656854              1  0.693147            32.0   \n",
       "\n",
       "   log_total_qty  sqrt_total_qty  unit_encoded  \n",
       "0       2.442347        3.240370            73  \n",
       "1       1.098612        1.414214            46  \n",
       "2       3.496508        5.656854            73  \n",
       "3       1.609438        2.000000            37  \n",
       "4       3.496508        5.656854            46  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:571\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[39m\n\u001b[32m    569\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Downloading Model\u001b[39;00m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m'\u001b[39m\u001b[33mhf-hub:Marqo/marqo-ecommerce-embeddings-L\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model, preprocess_train, preprocess_val = \u001b[43mopen_clip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model_and_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m tokenizer = open_clip.get_tokenizer(model_name)\n\u001b[32m      6\u001b[39m model = model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/open_clip/factory.py:930\u001b[39m, in \u001b[36mcreate_model_and_transforms\u001b[39m\u001b[34m(model_name, pretrained, load_weights, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, force_context_length, image_mean, image_std, image_interpolation, image_resize_mode, aug_cfg, pretrained_image, pretrained_text, pretrained_image_path, pretrained_text_path, cache_dir, output_dict, weights_only, **model_kwargs)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    856\u001b[39m \u001b[33;03mCreates a contrastive vision-language model along with preprocessing transforms for training and validation.\u001b[39;00m\n\u001b[32m    857\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    920\u001b[39m \u001b[33;03m    any random augmentation.\u001b[39;00m\n\u001b[32m    921\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    922\u001b[39m force_preprocess_cfg = merge_preprocess_kwargs(\n\u001b[32m    923\u001b[39m     {},\n\u001b[32m    924\u001b[39m     mean=image_mean,\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m     resize_mode=image_resize_mode,\n\u001b[32m    928\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m model = \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_quick_gelu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_quick_gelu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_custom_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_custom_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_patch_dropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_patch_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_image_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_image_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_preprocess_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_preprocess_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_context_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_context_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_image_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_image_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_text_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_text_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m pp_cfg = PreprocessCfg(**model.visual.preprocess_cfg)\n\u001b[32m    955\u001b[39m preprocess_train = image_transform_v2(\n\u001b[32m    956\u001b[39m     pp_cfg,\n\u001b[32m    957\u001b[39m     is_train=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    958\u001b[39m     aug_cfg=aug_cfg,\n\u001b[32m    959\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/open_clip/factory.py:382\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(model_name, pretrained, load_weights, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, force_preprocess_cfg, force_context_length, pretrained_image, pretrained_text, pretrained_image_path, pretrained_text_path, cache_dir, output_dict, require_pretrained, weights_only, **model_kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;66;03m# Attempt find default weights file from the Hub repo\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     checkpoint_path = \u001b[43mdownload_pretrained_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound default weights file on HF Hub: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e_weights:\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# Log warning if weights download fails, but proceed (might only need config)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/open_clip/pretrained.py:871\u001b[39m, in \u001b[36mdownload_pretrained_from_hf\u001b[39m\u001b[34m(model_id, filename, revision, cache_dir)\u001b[39m\n\u001b[32m    869\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m safe_filename \u001b[38;5;129;01min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m         cached_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    877\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cached_file\n\u001b[32m    878\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[39m\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    987\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    988\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         dry_run=dry_run,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1200\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1213\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1791\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, headers, expected_size, filename, force_download, etag, xet_file_data, tqdm_class)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1790\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1798\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1800\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:566\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[39m\n\u001b[32m    554\u001b[39m     displayed_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(…)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m progress_cm = _get_progress_bar_context(\n\u001b[32m    557\u001b[39m     desc=displayed_filename,\n\u001b[32m    558\u001b[39m     log_level=logger.getEffectiveLevel(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    563\u001b[39m     _tqdm_bar=_tqdm_bar,\n\u001b[32m    564\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m    569\u001b[39m         progress.update(progress_bytes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/amazon_ml_challenge_2025/.venv/lib/python3.12/site-packages/tqdm/std.py:1138\u001b[39m, in \u001b[36mtqdm.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Downloading Model\n",
    "model_name = 'hf-hub:Marqo/marqo-ecommerce-embeddings-L'\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(model_name)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/7] Generating Marqo Embeddings\n",
      "Processing training set...\n",
      "Batch size: 512, Num workers: 16, Prefetch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 147/147 [34:11<00:00, 13.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n",
      "Batch size: 512, Num workers: 16, Prefetch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 147/147 [24:21<00:00,  9.94s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings: (75000, 1024)\n",
      "Text embeddings: (75000, 1024)\n",
      "Combined embeddings: (75000, 2048)\n",
      "Embeddings saved to disk\n"
     ]
    }
   ],
   "source": [
    "# Generate Marqo Embeddings\n",
    "print(\"[5/7] Generating Marqo Embeddings\")\n",
    "\n",
    "# ==============================\n",
    "#  Dataset: Separate Text Columns\n",
    "# ==============================\n",
    "class EcommerceDataset(Dataset):\n",
    "    \"\"\"Optimized dataset for fast parallel loading with multi-text fields\"\"\"\n",
    "    def __init__(self, df, preprocess):\n",
    "        self.image_paths = df['image_path'].tolist()\n",
    "        self.item_names = df['item_name'].astype(str).tolist()\n",
    "        self.bullet_points = df['bullet_points'].astype(str).tolist()\n",
    "        self.descriptions = df['product_description'].astype(str).tolist()\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and preprocess image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = self.preprocess(img)\n",
    "        except:\n",
    "            # Fallback: white image if corrupt/missing\n",
    "            white_img = Image.new('RGB', (224, 224), color='white')\n",
    "            img_tensor = self.preprocess(white_img)\n",
    "\n",
    "        # Return all 3 text fields\n",
    "        item_name = self.item_names[idx]\n",
    "        bullet_points = self.bullet_points[idx]\n",
    "        description = self.descriptions[idx]\n",
    "\n",
    "        return img_tensor, item_name, bullet_points, description\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate to handle multiple text fields\"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    item_names = [item[1] for item in batch]\n",
    "    bullet_points = [item[2] for item in batch]\n",
    "    descriptions = [item[3] for item in batch]\n",
    "    return images, item_names, bullet_points, descriptions\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  Optimized Embedding Generator\n",
    "# ==============================\n",
    "def generate_embeddings_optimized(df, batch_size=512, text_weights=(0.6, 0.3, 0.1)):\n",
    "    \"\"\"\n",
    "    Generate embeddings with DataLoader optimization.\n",
    "    Now supports separate embeddings for item name, bullet points, and description.\n",
    "    text_weights controls how to combine them (weighted average).\n",
    "    \"\"\"\n",
    "    dataset = EcommerceDataset(df, preprocess_val)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=16,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=4,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    all_image_features = []\n",
    "    all_text_features = []\n",
    "\n",
    "    print(f\"Batch size: {batch_size}, Num workers: 16, Prefetch: 4\")\n",
    "    w_name, w_bullet, w_desc = text_weights\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, item_names, bullet_points, descriptions) in enumerate(\n",
    "            tqdm(dataloader, desc=\"Processing\")\n",
    "        ):\n",
    "            # Move images to GPU\n",
    "            images = images.to(device, non_blocking=True)\n",
    "\n",
    "            # Encode image embeddings\n",
    "            image_features = model.encode_image(images, normalize=True)\n",
    "\n",
    "            # Encode text fields separately\n",
    "            name_tokens = tokenizer(item_names).to(device)\n",
    "            bullet_tokens = tokenizer(bullet_points).to(device)\n",
    "            desc_tokens = tokenizer(descriptions).to(device)\n",
    "\n",
    "            name_features = model.encode_text(name_tokens, normalize=True)\n",
    "            bullet_features = model.encode_text(bullet_tokens, normalize=True)\n",
    "            desc_features = model.encode_text(desc_tokens, normalize=True)\n",
    "\n",
    "            # Weighted text fusion (default 0.6/0.3/0.1)\n",
    "            text_features = (\n",
    "                w_name * name_features +\n",
    "                w_bullet * bullet_features +\n",
    "                w_desc * desc_features\n",
    "            )\n",
    "            text_features = torch.nn.functional.normalize(text_features, dim=-1)\n",
    "\n",
    "            # Move to CPU\n",
    "            all_image_features.append(image_features.cpu())\n",
    "            all_text_features.append(text_features.cpu())\n",
    "\n",
    "            # Periodic cache cleanup\n",
    "            if batch_idx % 50 == 0 and batch_idx > 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Concatenate all batches\n",
    "    image_embeddings = torch.cat(all_image_features).numpy()\n",
    "    text_embeddings = torch.cat(all_text_features).numpy()\n",
    "\n",
    "    return image_embeddings, text_embeddings\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  Generate Train/Test Embeddings\n",
    "# ==============================\n",
    "print(\"Processing training set...\")\n",
    "train_img_emb, train_txt_emb = generate_embeddings_optimized(train_df, batch_size=512)\n",
    "\n",
    "print(\"Processing test set...\")\n",
    "test_img_emb, test_txt_emb = generate_embeddings_optimized(test_df, batch_size=512)\n",
    "\n",
    "print(f\"Image embeddings: {train_img_emb.shape}\")\n",
    "print(f\"Text embeddings: {train_txt_emb.shape}\")\n",
    "\n",
    "# Combine image + fused text embeddings\n",
    "train_embeddings = np.hstack([train_img_emb, train_txt_emb])\n",
    "test_embeddings = np.hstack([test_img_emb, test_txt_emb])\n",
    "\n",
    "print(f\"Combined embeddings: {train_embeddings.shape}\")\n",
    "\n",
    "# Save embeddings\n",
    "np.save('train_marqo_embeddings.npy', train_embeddings)\n",
    "np.save('test_marqo_embeddings.npy', test_embeddings)\n",
    "print(\"Embeddings saved to disk\")\n",
    "\n",
    "# Memory cleanup\n",
    "del model, tokenizer, preprocess_val\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/7] Combining Marqo embeddings + engineered features\n",
      "Final feature shape: (75000, 2057)\n",
      "Marqo embeddings: 2048\n",
      "Engineered features: 9\n"
     ]
    }
   ],
   "source": [
    "# Combining Features\n",
    "print(\"[6/7] Combining Marqo embeddings + engineered features\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "X_train = np.hstack([train_embeddings, train_features_scaled])\n",
    "X_test = np.hstack([test_embeddings, test_features_scaled])\n",
    "y_train = np.log1p(train_df['price'].values)\n",
    "\n",
    "print(f\"Final feature shape: {X_train.shape}\")\n",
    "print(f\"Marqo embeddings: {train_embeddings.shape[1]}\")\n",
    "print(f\"Engineered features: {train_features_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/7] Training XGBoost with 5-Fold CV on GPU...\n",
      "\n",
      "============================================================\n",
      "  FOLD 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1 SMAPE: 49.2047%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 2/5\n",
      "============================================================\n",
      "  Fold 2 SMAPE: 48.0522%\n",
      "  Best iteration: 4997\n",
      "\n",
      "============================================================\n",
      "  FOLD 3/5\n",
      "============================================================\n",
      "  Fold 3 SMAPE: 48.4541%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 4/5\n",
      "============================================================\n",
      "  Fold 4 SMAPE: 47.4840%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 5/5\n",
      "============================================================\n",
      "  Fold 5 SMAPE: 48.2107%\n",
      "  Best iteration: 4998\n",
      "\n",
      "================================================================================\n",
      "MARQO ECOMMERCE-L OOF SMAPE: 48.2811%\n",
      "================================================================================\n",
      "Fold scores: ['49.2047%', '48.0522%', '48.4541%', '47.4840%', '48.2107%']\n",
      "Fold std: 0.5614%\n",
      "Mean fold: 48.2811%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training XGB with 5-FOLD cross-validation on GPU\n",
    "print(\"[7/7] Training XGBoost with 5-Fold CV on GPU\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "# Optimized parameters for XGBoost with GPU\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.8,         \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'lambda': 0.2,            # L2 regularization (reg_lambda)\n",
    "    'alpha': 0.2,             # L1 regularization (reg_alpha)\n",
    "    'min_child_weight': 30,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0,\n",
    "\n",
    "    # --- GPU PARAMETERS ---\n",
    "    'tree_method': 'gpu_hist',   # Enables GPU acceleration for training\n",
    "    'predictor': 'gpu_predictor', # Enables GPU acceleration for prediction\n",
    "    # --------------------------\n",
    "}\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  FOLD {fold+1}/5\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Convert to DMatrix format required by xgb.train\n",
    "    dtrain = xgb.DMatrix(X_train[tr_idx], label=y_train[tr_idx])\n",
    "    dval = xgb.DMatrix(X_train[val_idx], label=y_train[val_idx])\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    #  Early stopping callback\n",
    "    early_stop_callback = xgb.callback.EarlyStopping(\n",
    "        rounds=100,\n",
    "        save_best=True  # Automatically saves the best iteration\n",
    "    )\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=5000,\n",
    "        evals=[(dval, 'validation')],\n",
    "        evals_result=evals_result,\n",
    "        callbacks=[early_stop_callback],\n",
    "        verbose_eval=False  # Suppress per-iteration output\n",
    "    )\n",
    "\n",
    "    # Predict (OOF and Test)\n",
    "    # Use best_iteration\n",
    "    best_iteration = model.best_iteration\n",
    "    dval_pred = xgb.DMatrix(X_train[val_idx])\n",
    "    dtest_pred = xgb.DMatrix(X_test)\n",
    "\n",
    "    # OOF Prediction: Use best_iteration directly\n",
    "    oof_preds[val_idx] = model.predict(dval_pred, iteration_range=(0, best_iteration))\n",
    "\n",
    "    # Test Prediction\n",
    "    test_preds += model.predict(dtest_pred, iteration_range=(0, best_iteration)) / 5\n",
    "\n",
    "    # Calculate SMAPE\n",
    "    # Un-log transform and clip prediction (log-transformed target -> price)\n",
    "    pred = np.maximum(np.expm1(oof_preds[val_idx]), 0.01)\n",
    "    true = np.expm1(y_train[val_idx])  # Un-log transform true label\n",
    "\n",
    "    # Correct SMAPE formula: uses average denominator\n",
    "    smape = 100 * np.mean(2 * np.abs(true - pred) / (np.abs(true) + np.abs(pred)))\n",
    "    fold_scores.append(smape)\n",
    "\n",
    "    print(f\"  Fold {fold+1} SMAPE: {smape:.4f}%\")\n",
    "    print(f\"  Best iteration: {best_iteration}\")\n",
    "\n",
    "# Overall SMAPE\n",
    "final_oof = np.maximum(np.expm1(oof_preds), 0.01)\n",
    "y_true = train_df['price'].values  # Use the original target for final SMAPE\n",
    "overall_smape = 100 * np.mean(2 * np.abs(y_true - final_oof) /\n",
    "                             (np.abs(y_true) + np.abs(final_oof)))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MARQO ECOMMERCE-L OOF SMAPE: {overall_smape:.4f}%\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fold scores: {[f'{s:.4f}%' for s in fold_scores]}\")\n",
    "print(f\"Fold std: {np.std(fold_scores):.4f}%\")\n",
    "print(f\"Mean fold: {np.mean(fold_scores):.4f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission File\n",
      "\n",
      "================================================================================\n",
      "PREDICTION STATISTICS\n",
      "================================================================================\n",
      "Mean price: $18.55\n",
      "Median price: $13.96\n",
      "Min price: $0.76\n",
      "Max price: $240.93\n",
      "Std: $16.81\n",
      "OOF SMAPE: 48.2811%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Submission File\n",
    "print(\"Generating Submission File\")\n",
    "\n",
    "final_test = np.maximum(np.expm1(test_preds), 0.01)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test_df['sample_id'],\n",
    "    'price': final_test\n",
    "})\n",
    "submission.to_csv('submission.csv',\n",
    "                 index=False, float_format='%.2f')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean price: ${final_test.mean():.2f}\")\n",
    "print(f\"Median price: ${np.median(final_test):.2f}\")\n",
    "print(f\"Min price: ${final_test.min():.2f}\")\n",
    "print(f\"Max price: ${final_test.max():.2f}\")\n",
    "print(f\"Std: ${final_test.std():.2f}\")\n",
    "print(f\"OOF SMAPE: {overall_smape:.4f}%\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_ml_challenge_2025 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
