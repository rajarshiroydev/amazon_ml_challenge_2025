{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import urllib\n",
    "import warnings\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import multiprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "VRAM: 79.1 GB\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Loading Data\n",
      "Train: 75,000, Test: 75,000\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "print(\"[1/7] Loading Data\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f\"Train: {len(train_df):,}, Test: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] Extracting item_name, bullet_points and product_description from catalog_content column\n"
     ]
    }
   ],
   "source": [
    "# Extracting item_name, bullet_points and product_description from catalog_content column\n",
    "print(\"[2/7] Extracting item_name, bullet_points and product_description from catalog_content column\")\n",
    "\n",
    "def extract_fields(text):\n",
    "    \"\"\"Extract Item Name, Bullet Points, and Product Description from the string.\"\"\"\n",
    "    item_name_match = re.search(r\"Item Name:\\s*(.+?)(?:\\n|$)\", text)\n",
    "    item_name = item_name_match.group(1).strip() if item_name_match else None\n",
    "\n",
    "    # Capture all bullet points with flexible numbering or single 'Bullet Point'\n",
    "    bullets = re.findall(r\"Bullet Point\\s*\\d*:\\s*(.+)\", text)\n",
    "    bullet_points = [b.strip() for b in bullets] if bullets else []\n",
    "\n",
    "    # Capture product description\n",
    "    prod_desc_match = re.search(r\"Product Description:\\s*(.+)\", text, re.DOTALL)\n",
    "    prod_desc = prod_desc_match.group(1).strip() if prod_desc_match else None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"item_name\": item_name,\n",
    "        \"bullet_points\": bullet_points if bullet_points else None,\n",
    "        \"product_description\": prod_desc\n",
    "    })\n",
    "\n",
    "# extract fields from product_description of train data\n",
    "df_extracted = train_df[\"catalog_content\"].apply(extract_fields)\n",
    "train_df = pd.concat([train_df, df_extracted], axis=1)\n",
    "\n",
    "# extract fields from product_description of test data\n",
    "df_extracted = test_df[\"catalog_content\"].apply(extract_fields)\n",
    "test_df = pd.concat([test_df, df_extracted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Downloading Images\n",
      "Downloading 75,000 train images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  49%|████▉     | 36880/75000 [00:01<00:01, 33079.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not able to download - https://m.media-amazon.com/images/I/51mjZYDYjyL.jpg\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 75000/75000 [00:02<00:00, 33292.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 75,000 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading:  54%|█████▍    | 40619/75000 [00:01<00:01, 31668.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not able to download - https://m.media-amazon.com/images/I/813CjSgHj0S.jpg\n",
      "HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 75000/75000 [00:02<00:00, 32606.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Dowloading Images\n",
    "print(\"[3/7] Downloading Images\")\n",
    "\n",
    "def download_image(image_link, savefolder):\n",
    "    if isinstance(image_link, str):\n",
    "        filename = Path(image_link).name\n",
    "        image_save_path = os.path.join(savefolder, filename)\n",
    "        if not os.path.exists(image_save_path):\n",
    "            try:\n",
    "                urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            except Exception as ex:\n",
    "                print(f'Warning: Not able to download - {image_link}\\n{ex}')\n",
    "        return image_save_path\n",
    "    return None\n",
    "\n",
    "def download_images(image_links, download_folder):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    results = []\n",
    "    download_image_partial = partial(download_image, savefolder=download_folder)\n",
    "\n",
    "    with multiprocessing.Pool(100) as pool:\n",
    "        for result in tqdm(pool.imap(download_image_partial, image_links),\n",
    "                          total=len(image_links), desc=\"Downloading\"):\n",
    "            results.append(result)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Download train images\n",
    "train_folder = 'train_images'\n",
    "print(f\"Downloading {len(train_df):,} train images...\")\n",
    "train_image_paths = download_images(train_df['image_link'].tolist(), train_folder)\n",
    "\n",
    "# Download test images\n",
    "test_folder = 'test_images'\n",
    "print(f\"Downloading {len(test_df):,} test images...\")\n",
    "test_image_paths = download_images(test_df['image_link'].tolist(), test_folder)\n",
    "\n",
    "print(\"All images downloaded!\")\n",
    "\n",
    "# Map URLs to local paths\n",
    "train_df['image_path'] = [os.path.join(train_folder, Path(url).name)\n",
    "                          if isinstance(url, str) else None\n",
    "                          for url in train_df['image_link']]\n",
    "test_df['image_path'] = [os.path.join(test_folder, Path(url).name)\n",
    "                         if isinstance(url, str) else None\n",
    "                         for url in test_df['image_link']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>price</th>\n",
       "      <th>item_name</th>\n",
       "      <th>bullet_points</th>\n",
       "      <th>product_description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33127</td>\n",
       "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>La Victoria Green Taco Sauce Mild, 12 Ounce (P...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/51mo8htwTHL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198967</td>\n",
       "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>13.12</td>\n",
       "      <td>Salerno Cookies, The Original Butter Cookies, ...</td>\n",
       "      <td>[Original Butter Cookies: Classic butter cooki...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/71YtriIHAAL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261251</td>\n",
       "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Bear Creek Hearty Soup Bowl, Creamy Chicken wi...</td>\n",
       "      <td>[Loaded with hearty long grain wild rice and v...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/51+PFEe-w-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55858</td>\n",
       "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>30.34</td>\n",
       "      <td>Judee’s Blue Cheese Powder 11.25 oz - Gluten-F...</td>\n",
       "      <td>[Add to your favorite appetizers, dips &amp; sprea...</td>\n",
       "      <td>Judees Powdered Blue Cheese cheddar cheese pow...</td>\n",
       "      <td>train_images/41mu0HAToDL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292686</td>\n",
       "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>66.49</td>\n",
       "      <td>kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...</td>\n",
       "      <td>[kedem Sherry Cooking Wine, 12.7 Ounce - 12 pe...</td>\n",
       "      <td>None</td>\n",
       "      <td>train_images/41sA037+QvL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
       "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
       "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
       "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
       "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
       "\n",
       "                                          image_link  price  \\\n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89   \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12   \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97   \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34   \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49   \n",
       "\n",
       "                                           item_name  \\\n",
       "0  La Victoria Green Taco Sauce Mild, 12 Ounce (P...   \n",
       "1  Salerno Cookies, The Original Butter Cookies, ...   \n",
       "2  Bear Creek Hearty Soup Bowl, Creamy Chicken wi...   \n",
       "3  Judee’s Blue Cheese Powder 11.25 oz - Gluten-F...   \n",
       "4  kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...   \n",
       "\n",
       "                                       bullet_points  \\\n",
       "0                                               None   \n",
       "1  [Original Butter Cookies: Classic butter cooki...   \n",
       "2  [Loaded with hearty long grain wild rice and v...   \n",
       "3  [Add to your favorite appetizers, dips & sprea...   \n",
       "4  [kedem Sherry Cooking Wine, 12.7 Ounce - 12 pe...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  Judees Powdered Blue Cheese cheddar cheese pow...   \n",
       "4                                               None   \n",
       "\n",
       "                     image_path  \n",
       "0  train_images/51mo8htwTHL.jpg  \n",
       "1  train_images/71YtriIHAAL.jpg  \n",
       "2  train_images/51+PFEe-w-L.jpg  \n",
       "3  train_images/41mu0HAToDL.jpg  \n",
       "4  train_images/41sA037+QvL.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>item_name</th>\n",
       "      <th>bullet_points</th>\n",
       "      <th>product_description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100179</td>\n",
       "      <td>Item Name: Rani 14-Spice Eshamaya's Mango Chut...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71hoAn78AW...</td>\n",
       "      <td>Rani 14-Spice Eshamaya's Mango Chutney (Indian...</td>\n",
       "      <td>[You'll LOVE our 14-Spice Eshamaya's Mango Chu...</td>\n",
       "      <td>Mango chutney is made from diced green mangoes...</td>\n",
       "      <td>test_images/71hoAn78AWL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245611</td>\n",
       "      <td>Item Name: Natural MILK TEA Flavoring extract ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61ex8NHCIj...</td>\n",
       "      <td>Natural MILK TEA Flavoring extract by HALO PAN...</td>\n",
       "      <td>[Authentic Tasting, Asian-Inspired Natural fla...</td>\n",
       "      <td>Check our popular Milk Tea flavoring extract i...</td>\n",
       "      <td>test_images/61ex8NHCIjL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146263</td>\n",
       "      <td>Item Name: Honey Filled Hard Candy - Bulk Pack...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61KCM61J8e...</td>\n",
       "      <td>Honey Filled Hard Candy - Bulk Pack 2 Pounds -...</td>\n",
       "      <td>[Honey Filled Hard Candy; 2-pound bulk pack; a...</td>\n",
       "      <td>Honey Filled Hard Candy - Bulk Pack 2 Pounds -...</td>\n",
       "      <td>test_images/61KCM61J8eL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95658</td>\n",
       "      <td>Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51Ex6uOH7y...</td>\n",
       "      <td>Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>test_images/51Ex6uOH7yL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36806</td>\n",
       "      <td>Item Name: McCormick Culinary Vanilla Extract,...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QYlrOMoS...</td>\n",
       "      <td>McCormick Culinary Vanilla Extract, 32 fl oz -...</td>\n",
       "      <td>[PREMIUM INGREDIENTS: McCormick Culinary Pure ...</td>\n",
       "      <td>None</td>\n",
       "      <td>test_images/71QYlrOMoSL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0     100179  Item Name: Rani 14-Spice Eshamaya's Mango Chut...   \n",
       "1     245611  Item Name: Natural MILK TEA Flavoring extract ...   \n",
       "2     146263  Item Name: Honey Filled Hard Candy - Bulk Pack...   \n",
       "3      95658  Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz...   \n",
       "4      36806  Item Name: McCormick Culinary Vanilla Extract,...   \n",
       "\n",
       "                                          image_link  \\\n",
       "0  https://m.media-amazon.com/images/I/71hoAn78AW...   \n",
       "1  https://m.media-amazon.com/images/I/61ex8NHCIj...   \n",
       "2  https://m.media-amazon.com/images/I/61KCM61J8e...   \n",
       "3  https://m.media-amazon.com/images/I/51Ex6uOH7y...   \n",
       "4  https://m.media-amazon.com/images/I/71QYlrOMoS...   \n",
       "\n",
       "                                           item_name  \\\n",
       "0  Rani 14-Spice Eshamaya's Mango Chutney (Indian...   \n",
       "1  Natural MILK TEA Flavoring extract by HALO PAN...   \n",
       "2  Honey Filled Hard Candy - Bulk Pack 2 Pounds -...   \n",
       "3    Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)   \n",
       "4  McCormick Culinary Vanilla Extract, 32 fl oz -...   \n",
       "\n",
       "                                       bullet_points  \\\n",
       "0  [You'll LOVE our 14-Spice Eshamaya's Mango Chu...   \n",
       "1  [Authentic Tasting, Asian-Inspired Natural fla...   \n",
       "2  [Honey Filled Hard Candy; 2-pound bulk pack; a...   \n",
       "3                                               None   \n",
       "4  [PREMIUM INGREDIENTS: McCormick Culinary Pure ...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Mango chutney is made from diced green mangoes...   \n",
       "1  Check our popular Milk Tea flavoring extract i...   \n",
       "2  Honey Filled Hard Candy - Bulk Pack 2 Pounds -...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                    image_path  \n",
       "0  test_images/71hoAn78AWL.jpg  \n",
       "1  test_images/61ex8NHCIjL.jpg  \n",
       "2  test_images/61KCM61J8eL.jpg  \n",
       "3  test_images/51Ex6uOH7yL.jpg  \n",
       "4  test_images/71QYlrOMoSL.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\n",
      "Value: 72.0\n",
      "Unit: Fl Oz\n",
      "\n",
      "Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\n",
      "Bullet Point 1: Original Butter Cookies: Classic butter cookies made with real butter\n",
      "Bullet Point 2: Variety Pack: Includes 4 boxes with 32 cookies total\n",
      "Bullet Point 3: Occasion Perfect: Delicious cookies for birthdays, weddings, anniversaries\n",
      "Bullet Point 4: Shareable Treats: Fun to give and enjoy with friends and family\n",
      "Bullet Point 5: Salerno Brand: Trusted brand of delicious butter cookies since 1925\n",
      "Value: 32.0\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\n",
      "Bullet Point 1: Loaded with hearty long grain wild rice and vegetables\n",
      "Bullet Point 2: Full of hearty goodness\n",
      "Bullet Point 3: Single serve bowls\n",
      "Bullet Point 4: Easy to prepare mix\n",
      "Bullet Point 5: 0 grams trans fat\n",
      "Value: 11.4\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: Judee’s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings and Salad Dressings - Great for Dips, Spreads and Sauces - Made in USA\n",
      "Bullet Point 1: Add to your favorite appetizers, dips & spreads. Use to season popcorn or warmed pita chips.\n",
      "Bullet Point 2: Sprinkle over french fries, fried chicken, mashed potatoes, roasted veggies, pasta, and more\n",
      "Bullet Point 3: Made in a dedicated gluten-free facility and shipped in a standup, resealable pouch to ensure freshness\n",
      "Bullet Point 4: Ingredients: Blue Cheese (Milk, Salt, Cultures, & Enzymes) and Disodium Phosphate\n",
      "Bullet Point 5: Since 2009, Judee’s has been dedicated to providing fresh, allergy-conscious ingredients, great for your recipes and even better for your family\n",
      "Product Description: Judees Powdered Blue Cheese cheddar cheese powder is an alternative to mozzarella cheese shredded or american cheese slices deli. Make your own alfredo sauce with heavy cream and black buffalo dip with this powder. It adds extra flavor to salad dressing like ranch dressing and great on pizza dough or cauliflower pasta. Add to macaroni and cheese or popcorn seasoning for more aroma and cheesy feel. Combine with mustard and other ingredients to create your own dressing for buffalo chicken or buffalo wings.\n",
      "Value: 11.25\n",
      "Unit: Ounce\n",
      "\n",
      "Item Name: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\n",
      "Bullet Point: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\n",
      "Value: 12.0\n",
      "Unit: Count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the fields present in content_catalog column\n",
    "content_catalog = list(train_df.catalog_content)\n",
    "for i in content_catalog[:5]:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`content_catalog column has Item Name, Bullet Point, Product Description, Value and Unit. All observations do not have all the fields.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/7] Engineering Value/Unit features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train features: 100%|██████████| 75000/75000 [00:03<00:00, 18950.01it/s]\n",
      "Test features: 100%|██████████| 75000/75000 [00:03<00:00, 19271.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 engineered features\n",
      "Top correlations with price:\n",
      "price             1.000000\n",
      "sqrt_value        0.163218\n",
      "log_value         0.126561\n",
      "log_total_qty     0.107146\n",
      "unit_encoded      0.089220\n",
      "value             0.064510\n",
      "log_pack          0.046921\n",
      "sqrt_total_qty    0.000456\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print(\"[4/7] Engineering Value/Unit features...\")\n",
    "\n",
    "def extract_value_unit_features(text):\n",
    "    \"\"\"Extract critical numeric features with high price correlation\"\"\"\n",
    "    features = {}\n",
    "    text_str = str(text)\n",
    "\n",
    "    # Extract Value\n",
    "    value_match = re.search(r'Value:\\s*([\\d.]+)', text_str)\n",
    "    value = float(value_match.group(1)) if value_match else 0\n",
    "\n",
    "    # Extract Unit\n",
    "    unit_match = re.search(r'Unit:\\s*([^\\n]+)', text_str)\n",
    "    unit = unit_match.group(1).strip() if unit_match else 'unknown'\n",
    "\n",
    "    # Pack quantity patterns\n",
    "    pack_patterns = [\n",
    "        r'pack of (\\d+)', r'\\(pack of (\\d+)\\)', r'(\\d+)[- ]pack',\n",
    "        r'(\\d+) count', r'set of (\\d+)', r'case of (\\d+)',\n",
    "    ]\n",
    "    pack_qty = 1\n",
    "    for pattern in pack_patterns:\n",
    "        matches = re.findall(pattern, text_str.lower())\n",
    "        if matches:\n",
    "            pack_qty = max(pack_qty, max([int(m) for m in matches]))\n",
    "\n",
    "    # Create features\n",
    "    features['value'] = value\n",
    "    features['log_value'] = np.log1p(value)\n",
    "    features['sqrt_value'] = np.sqrt(value)\n",
    "    features['pack_quantity'] = pack_qty\n",
    "    features['log_pack'] = np.log1p(pack_qty)\n",
    "    features['total_quantity'] = value * pack_qty\n",
    "    features['log_total_qty'] = np.log1p(value * pack_qty)\n",
    "    features['sqrt_total_qty'] = np.sqrt(value * pack_qty)\n",
    "    features['unit'] = unit\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = pd.DataFrame([extract_value_unit_features(t)\n",
    "                               for t in tqdm(train_df['catalog_content'],\n",
    "                                           desc=\"Train features\")])\n",
    "test_features = pd.DataFrame([extract_value_unit_features(t)\n",
    "                             for t in tqdm(test_df['catalog_content'],\n",
    "                                         desc=\"Test features\")])\n",
    "\n",
    "# Encode units\n",
    "le = LabelEncoder()\n",
    "all_units = pd.concat([train_features['unit'], test_features['unit']])\n",
    "le.fit(all_units.astype(str))\n",
    "train_features['unit_encoded'] = le.transform(train_features['unit'].astype(str))\n",
    "test_features['unit_encoded'] = le.transform(test_features['unit'].astype(str))\n",
    "\n",
    "train_features = train_features.drop('unit', axis=1)\n",
    "test_features = test_features.drop('unit', axis=1)\n",
    "\n",
    "print(f\"{train_features.shape[1]} engineered features\")\n",
    "\n",
    "# Show correlations\n",
    "train_with_price = train_features.copy()\n",
    "train_with_price['price'] = train_df['price']\n",
    "print(\"Top correlations with price:\")\n",
    "print(train_with_price.corr()['price'].abs().sort_values(ascending=False).head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>sqrt_value</th>\n",
       "      <th>pack_quantity</th>\n",
       "      <th>log_pack</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>log_total_qty</th>\n",
       "      <th>sqrt_total_qty</th>\n",
       "      <th>unit_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.00</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>8.485281</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>432.00</td>\n",
       "      <td>6.070738</td>\n",
       "      <td>20.784610</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.00</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>4</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>128.00</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>11.313708</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.40</td>\n",
       "      <td>2.517696</td>\n",
       "      <td>3.376389</td>\n",
       "      <td>6</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>68.40</td>\n",
       "      <td>4.239887</td>\n",
       "      <td>8.270429</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.25</td>\n",
       "      <td>2.505526</td>\n",
       "      <td>3.354102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>11.25</td>\n",
       "      <td>2.505526</td>\n",
       "      <td>3.354102</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.00</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  log_value  sqrt_value  pack_quantity  log_pack  total_quantity  \\\n",
       "0  72.00   4.290459    8.485281              6  1.945910          432.00   \n",
       "1  32.00   3.496508    5.656854              4  1.609438          128.00   \n",
       "2  11.40   2.517696    3.376389              6  1.945910           68.40   \n",
       "3  11.25   2.505526    3.354102              1  0.693147           11.25   \n",
       "4  12.00   2.564949    3.464102              1  0.693147           12.00   \n",
       "\n",
       "   log_total_qty  sqrt_total_qty  unit_encoded  \n",
       "0       6.070738       20.784610            46  \n",
       "1       4.859812       11.313708            73  \n",
       "2       4.239887        8.270429            73  \n",
       "3       2.505526        3.354102            73  \n",
       "4       2.564949        3.464102            37  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>log_value</th>\n",
       "      <th>sqrt_value</th>\n",
       "      <th>pack_quantity</th>\n",
       "      <th>log_pack</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>log_total_qty</th>\n",
       "      <th>sqrt_total_qty</th>\n",
       "      <th>unit_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.5</td>\n",
       "      <td>2.442347</td>\n",
       "      <td>3.240370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.442347</td>\n",
       "      <td>3.240370</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  log_value  sqrt_value  pack_quantity  log_pack  total_quantity  \\\n",
       "0   10.5   2.442347    3.240370              1  0.693147            10.5   \n",
       "1    2.0   1.098612    1.414214              1  0.693147             2.0   \n",
       "2   32.0   3.496508    5.656854              1  0.693147            32.0   \n",
       "3    2.0   1.098612    1.414214              2  1.098612             4.0   \n",
       "4   32.0   3.496508    5.656854              1  0.693147            32.0   \n",
       "\n",
       "   log_total_qty  sqrt_total_qty  unit_encoded  \n",
       "0       2.442347        3.240370            73  \n",
       "1       1.098612        1.414214            46  \n",
       "2       3.496508        5.656854            73  \n",
       "3       1.609438        2.000000            37  \n",
       "4       3.496508        5.656854            46  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Model\n",
    "model_name = 'hf-hub:Marqo/marqo-ecommerce-embeddings-L'\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(model_name)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/7] Generating Marqo Embeddings\n",
      "Processing training set...\n",
      "Batch size: 512, Num workers: 16, Prefetch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 147/147 [34:11<00:00, 13.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n",
      "Batch size: 512, Num workers: 16, Prefetch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 147/147 [24:21<00:00,  9.94s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings: (75000, 1024)\n",
      "Text embeddings: (75000, 1024)\n",
      "Combined embeddings: (75000, 2048)\n",
      "Embeddings saved to disk\n"
     ]
    }
   ],
   "source": [
    "# Generate Marqo Embeddings\n",
    "print(\"[5/7] Generating Marqo Embeddings\")\n",
    "\n",
    "# ==============================\n",
    "#  Dataset: Separate Text Columns\n",
    "# ==============================\n",
    "class EcommerceDataset(Dataset):\n",
    "    \"\"\"Optimized dataset for fast parallel loading with multi-text fields\"\"\"\n",
    "    def __init__(self, df, preprocess):\n",
    "        self.image_paths = df['image_path'].tolist()\n",
    "        self.item_names = df['item_name'].astype(str).tolist()\n",
    "        self.bullet_points = df['bullet_points'].astype(str).tolist()\n",
    "        self.descriptions = df['product_description'].astype(str).tolist()\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and preprocess image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = self.preprocess(img)\n",
    "        except:\n",
    "            # Fallback: white image if corrupt/missing\n",
    "            white_img = Image.new('RGB', (224, 224), color='white')\n",
    "            img_tensor = self.preprocess(white_img)\n",
    "\n",
    "        # Return all 3 text fields\n",
    "        item_name = self.item_names[idx]\n",
    "        bullet_points = self.bullet_points[idx]\n",
    "        description = self.descriptions[idx]\n",
    "\n",
    "        return img_tensor, item_name, bullet_points, description\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate to handle multiple text fields\"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    item_names = [item[1] for item in batch]\n",
    "    bullet_points = [item[2] for item in batch]\n",
    "    descriptions = [item[3] for item in batch]\n",
    "    return images, item_names, bullet_points, descriptions\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  Optimized Embedding Generator\n",
    "# ==============================\n",
    "def generate_embeddings_optimized(df, batch_size=512, text_weights=(0.6, 0.3, 0.1)):\n",
    "    \"\"\"\n",
    "    Generate embeddings with DataLoader optimization.\n",
    "    Now supports separate embeddings for item name, bullet points, and description.\n",
    "    text_weights controls how to combine them (weighted average).\n",
    "    \"\"\"\n",
    "    dataset = EcommerceDataset(df, preprocess_val)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=16,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=4,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    all_image_features = []\n",
    "    all_text_features = []\n",
    "\n",
    "    print(f\"Batch size: {batch_size}, Num workers: 16, Prefetch: 4\")\n",
    "    w_name, w_bullet, w_desc = text_weights\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, item_names, bullet_points, descriptions) in enumerate(\n",
    "            tqdm(dataloader, desc=\"Processing\")\n",
    "        ):\n",
    "            # Move images to GPU\n",
    "            images = images.to(device, non_blocking=True)\n",
    "\n",
    "            # Encode image embeddings\n",
    "            image_features = model.encode_image(images, normalize=True)\n",
    "\n",
    "            # Encode text fields separately\n",
    "            name_tokens = tokenizer(item_names).to(device)\n",
    "            bullet_tokens = tokenizer(bullet_points).to(device)\n",
    "            desc_tokens = tokenizer(descriptions).to(device)\n",
    "\n",
    "            name_features = model.encode_text(name_tokens, normalize=True)\n",
    "            bullet_features = model.encode_text(bullet_tokens, normalize=True)\n",
    "            desc_features = model.encode_text(desc_tokens, normalize=True)\n",
    "\n",
    "            # Weighted text fusion (default 0.6/0.3/0.1)\n",
    "            text_features = (\n",
    "                w_name * name_features +\n",
    "                w_bullet * bullet_features +\n",
    "                w_desc * desc_features\n",
    "            )\n",
    "            text_features = torch.nn.functional.normalize(text_features, dim=-1)\n",
    "\n",
    "            # Move to CPU\n",
    "            all_image_features.append(image_features.cpu())\n",
    "            all_text_features.append(text_features.cpu())\n",
    "\n",
    "            # Periodic cache cleanup\n",
    "            if batch_idx % 50 == 0 and batch_idx > 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Concatenate all batches\n",
    "    image_embeddings = torch.cat(all_image_features).numpy()\n",
    "    text_embeddings = torch.cat(all_text_features).numpy()\n",
    "\n",
    "    return image_embeddings, text_embeddings\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  Generate Train/Test Embeddings\n",
    "# ==============================\n",
    "print(\"Processing training set...\")\n",
    "train_img_emb, train_txt_emb = generate_embeddings_optimized(train_df, batch_size=512)\n",
    "\n",
    "print(\"Processing test set...\")\n",
    "test_img_emb, test_txt_emb = generate_embeddings_optimized(test_df, batch_size=512)\n",
    "\n",
    "print(f\"Image embeddings: {train_img_emb.shape}\")\n",
    "print(f\"Text embeddings: {train_txt_emb.shape}\")\n",
    "\n",
    "# Combine image + fused text embeddings\n",
    "train_embeddings = np.hstack([train_img_emb, train_txt_emb])\n",
    "test_embeddings = np.hstack([test_img_emb, test_txt_emb])\n",
    "\n",
    "print(f\"Combined embeddings: {train_embeddings.shape}\")\n",
    "\n",
    "# Save embeddings\n",
    "np.save('train_marqo_embeddings.npy', train_embeddings)\n",
    "np.save('test_marqo_embeddings.npy', test_embeddings)\n",
    "print(\"Embeddings saved to disk\")\n",
    "\n",
    "# Memory cleanup\n",
    "del model, tokenizer, preprocess_val\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/7] Combining Marqo embeddings + engineered features\n",
      "Final feature shape: (75000, 2057)\n",
      "Marqo embeddings: 2048\n",
      "Engineered features: 9\n"
     ]
    }
   ],
   "source": [
    "# Combining Features\n",
    "print(\"[6/7] Combining Marqo embeddings + engineered features\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "X_train = np.hstack([train_embeddings, train_features_scaled])\n",
    "X_test = np.hstack([test_embeddings, test_features_scaled])\n",
    "y_train = np.log1p(train_df['price'].values)\n",
    "\n",
    "print(f\"Final feature shape: {X_train.shape}\")\n",
    "print(f\"Marqo embeddings: {train_embeddings.shape[1]}\")\n",
    "print(f\"Engineered features: {train_features_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/7] Training XGBoost with 5-Fold CV on GPU...\n",
      "\n",
      "============================================================\n",
      "  FOLD 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1 SMAPE: 49.2047%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 2/5\n",
      "============================================================\n",
      "  Fold 2 SMAPE: 48.0522%\n",
      "  Best iteration: 4997\n",
      "\n",
      "============================================================\n",
      "  FOLD 3/5\n",
      "============================================================\n",
      "  Fold 3 SMAPE: 48.4541%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 4/5\n",
      "============================================================\n",
      "  Fold 4 SMAPE: 47.4840%\n",
      "  Best iteration: 4999\n",
      "\n",
      "============================================================\n",
      "  FOLD 5/5\n",
      "============================================================\n",
      "  Fold 5 SMAPE: 48.2107%\n",
      "  Best iteration: 4998\n",
      "\n",
      "================================================================================\n",
      "MARQO ECOMMERCE-L OOF SMAPE: 48.2811%\n",
      "================================================================================\n",
      "Fold scores: ['49.2047%', '48.0522%', '48.4541%', '47.4840%', '48.2107%']\n",
      "Fold std: 0.5614%\n",
      "Mean fold: 48.2811%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training XGB with 5-FOLD cross-validation on GPU\n",
    "print(\"[7/7] Training XGBoost with 5-Fold CV on GPU\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "# Optimized parameters for XGBoost with GPU\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.8,         \n",
    "    'colsample_bytree': 0.8,  \n",
    "    'lambda': 0.2,            # L2 regularization (reg_lambda)\n",
    "    'alpha': 0.2,             # L1 regularization (reg_alpha)\n",
    "    'min_child_weight': 30,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0,\n",
    "\n",
    "    # --- GPU PARAMETERS ---\n",
    "    'tree_method': 'gpu_hist',   # Enables GPU acceleration for training\n",
    "    'predictor': 'gpu_predictor', # Enables GPU acceleration for prediction\n",
    "    # --------------------------\n",
    "}\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  FOLD {fold+1}/5\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Convert to DMatrix format required by xgb.train\n",
    "    dtrain = xgb.DMatrix(X_train[tr_idx], label=y_train[tr_idx])\n",
    "    dval = xgb.DMatrix(X_train[val_idx], label=y_train[val_idx])\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    #  Early stopping callback\n",
    "    early_stop_callback = xgb.callback.EarlyStopping(\n",
    "        rounds=100,\n",
    "        save_best=True  # Automatically saves the best iteration\n",
    "    )\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=5000,\n",
    "        evals=[(dval, 'validation')],\n",
    "        evals_result=evals_result,\n",
    "        callbacks=[early_stop_callback],\n",
    "        verbose_eval=False  # Suppress per-iteration output\n",
    "    )\n",
    "\n",
    "    # Predict (OOF and Test)\n",
    "    # Use best_iteration\n",
    "    best_iteration = model.best_iteration\n",
    "    dval_pred = xgb.DMatrix(X_train[val_idx])\n",
    "    dtest_pred = xgb.DMatrix(X_test)\n",
    "\n",
    "    # OOF Prediction: Use best_iteration directly\n",
    "    oof_preds[val_idx] = model.predict(dval_pred, iteration_range=(0, best_iteration))\n",
    "\n",
    "    # Test Prediction\n",
    "    test_preds += model.predict(dtest_pred, iteration_range=(0, best_iteration)) / 5\n",
    "\n",
    "    # Calculate SMAPE\n",
    "    # Un-log transform and clip prediction (log-transformed target -> price)\n",
    "    pred = np.maximum(np.expm1(oof_preds[val_idx]), 0.01)\n",
    "    true = np.expm1(y_train[val_idx])  # Un-log transform true label\n",
    "\n",
    "    # Correct SMAPE formula: uses average denominator\n",
    "    smape = 100 * np.mean(2 * np.abs(true - pred) / (np.abs(true) + np.abs(pred)))\n",
    "    fold_scores.append(smape)\n",
    "\n",
    "    print(f\"  Fold {fold+1} SMAPE: {smape:.4f}%\")\n",
    "    print(f\"  Best iteration: {best_iteration}\")\n",
    "\n",
    "# Overall SMAPE\n",
    "final_oof = np.maximum(np.expm1(oof_preds), 0.01)\n",
    "y_true = train_df['price'].values  # Use the original target for final SMAPE\n",
    "overall_smape = 100 * np.mean(2 * np.abs(y_true - final_oof) /\n",
    "                             (np.abs(y_true) + np.abs(final_oof)))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MARQO ECOMMERCE-L OOF SMAPE: {overall_smape:.4f}%\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fold scores: {[f'{s:.4f}%' for s in fold_scores]}\")\n",
    "print(f\"Fold std: {np.std(fold_scores):.4f}%\")\n",
    "print(f\"Mean fold: {np.mean(fold_scores):.4f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission File\n",
      "\n",
      "================================================================================\n",
      "PREDICTION STATISTICS\n",
      "================================================================================\n",
      "Mean price: $18.55\n",
      "Median price: $13.96\n",
      "Min price: $0.76\n",
      "Max price: $240.93\n",
      "Std: $16.81\n",
      "OOF SMAPE: 48.2811%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Submission File\n",
    "print(\"Generating Submission File\")\n",
    "\n",
    "final_test = np.maximum(np.expm1(test_preds), 0.01)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test_df['sample_id'],\n",
    "    'price': final_test\n",
    "})\n",
    "submission.to_csv('submission.csv',\n",
    "                 index=False, float_format='%.2f')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean price: ${final_test.mean():.2f}\")\n",
    "print(f\"Median price: ${np.median(final_test):.2f}\")\n",
    "print(f\"Min price: ${final_test.min():.2f}\")\n",
    "print(f\"Max price: ${final_test.max():.2f}\")\n",
    "print(f\"Std: ${final_test.std():.2f}\")\n",
    "print(f\"OOF SMAPE: {overall_smape:.4f}%\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_ml_challenge_2025 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
